# -*- coding: utf-8 -*-
"""digit_recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j-xeVNJ5H3VDwkaV0Wy95FoiI-2gqodv
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cv2
from sklearn.metrics import accuracy_score
# %pip install python-mnist

import tensorflow as tf

# Load the MNIST dataset
(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()

ar_features = np.array(train_images)
ar_labels = np.array(train_labels)
ar_features.shape, ar_labels.shape

from collections import Counter

# Count the number of samples for each class
class_counts = Counter(train_labels)

# Display the count for each class
for label, count in sorted(class_counts.items()):
    print(f"Class {label}: {count} samples")

labels = sorted(class_counts.keys())  # Digits 0-9
counts = [class_counts[label] for label in labels]

# Plot the bar chart
plt.figure(figsize=(10, 6))
plt.bar(labels, counts, color='skyblue', alpha=0.8)

# Adding labels, title, and grid
plt.xlabel('Digit Class', fontsize=14)
plt.ylabel('Number of Samples', fontsize=14)
plt.title('Distribution of Samples per Digit Class', fontsize=16)
plt.xticks(labels, fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Show the plot
plt.tight_layout()
plt.show()

# Get the number of test samples
num_test_samples = test_images.shape[0]

print("Number of test samples in the MNIST dataset:", num_test_samples)

# Flatten the images (from 28x28 to 784 features) for SVM input
ar_features = train_images.reshape((train_images.shape[0], -1))
ar_labels = train_labels

# Test data
test_features = test_images.reshape((test_images.shape[0], -1))
test_labels = test_labels

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, accuracy_score

# Initialize the Random Forest classifier
clf = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the Random Forest model
clf.fit(ar_features, ar_labels)

# Predict on training data
predictions = clf.predict(ar_features)

# Compute confusion matrix
cm = confusion_matrix(ar_labels, predictions)
print("Confusion Matrix:\n", cm)

# Compute statistics
accuracy = accuracy_score(ar_labels, predictions)
print("Overall Accuracy is", round(accuracy, 2))

test_predictions = clf.predict(test_features)
# Print the first 10 predictions
print("Predictions on Test Data:", test_predictions[:20])

# Print the corresponding true labels for comparison
print("True Labels:", test_labels[:20])

test_predictions = clf.predict(test_features)

# Print the first 10 predictions and corresponding true labels
print("Predictions on Test Data:", test_predictions[:10])
print("True Labels:", test_labels[:10])

# Check if the predictions are correct
comparison = test_predictions[:10] == test_labels[:10]
print("Comparison (True = Correct, False = Incorrect):", comparison)

# Evaluate the model performance
test_accuracy = accuracy_score(test_labels, test_predictions)
print("\nTest Accuracy:", round(test_accuracy, 2))

# Print the confusion matrix
test_cm = confusion_matrix(test_labels, test_predictions)
print("\nConfusion Matrix:\n", test_cm)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, accuracy_score

# Initialize the K-Nearest Neighbors classifier
knn_clf = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors (k) as needed

# Train the KNN model
knn_clf.fit(ar_features, ar_labels)

# Predict on training data
knn_predictions = knn_clf.predict(ar_features)

# Compute confusion matrix
knn_cm = confusion_matrix(ar_labels, knn_predictions)
print("Confusion Matrix:\n", knn_cm)

# Compute accuracy
knn_accuracy = accuracy_score(ar_labels, knn_predictions)
print("Overall Accuracy is", round(knn_accuracy, 2))

test_predictions = clf.predict(test_features)
# Print the first 10 predictions
print("Predictions on Test Data:", test_predictions[:10])

# Print the corresponding true labels for comparison
print("True Labels:", test_labels[:10])

# Make predictions on the test data
knn_predictions = knn_clf.predict(test_features)
print("KNN Predictions on Test Data:", knn_predictions[:10])
print("True Labels:", test_labels[:10])

# Check if the predictions are correct
knn_comparison = knn_predictions[:10] == test_labels[:10]
print("Comparison (True = Correct, False = Incorrect):", knn_comparison)

# Evaluate the model performance
knn_accuracy = accuracy_score(test_labels, knn_predictions)
print("\nKNN Test Accuracy:", round(knn_accuracy, 2))

# Print the confusion matrix
knn_cm = confusion_matrix(test_labels, knn_predictions)
print("\nKNN Confusion Matrix:\n", knn_cm)

# Prepare data for accuracy comparison
model_names = ['Random Forest', 'KNN']
train_accuracies = [accuracy, knn_accuracy]
test_accuracies = [test_accuracy, knn_accuracy]

# Bar plot for accuracy comparison
x = np.arange(len(model_names))  # Number of models
width = 0.35

plt.figure(figsize=(8, 6))
plt.bar(x - width/2, train_accuracies, width, label='Train Accuracy', color='skyblue')
plt.bar(x + width/2, test_accuracies, width, label='Test Accuracy', color='orange')
plt.xticks(x, model_names)
plt.title("Model Accuracy Comparison")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Read the input image
image_path = "images.jpg"
im = cv2.imread(image_path)

if im is None:
    print("Error: Image not loaded.")
else:
    print("Image loaded successfully!")

# Convert to grayscale and apply Gaussian filtering
im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
im_gray = cv2.GaussianBlur(im_gray, (5, 5), 0)
#plt.imshow(im_gray)
#plt.show()

# Threshold the image
_, im_th = cv2.threshold(im_gray, 90, 255, cv2.THRESH_BINARY_INV)
#plt.imshow(im_th)
# Find contours in the image
contours, _ = cv2.findContours(im_th.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# Get rectangles containing each contour
rects = [cv2.boundingRect(ctr) for ctr in contours]

# Process each rectangle
for rect in rects:
    # Draw the rectangles
    cv2.rectangle(im, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 1)

    # Extract the region of interest (ROI)
    leng = int(rect[3] * 1.6)
    pt1 = max(rect[1] + rect[3] // 2 - leng // 2, 0)
    pt2 = max(rect[0] + rect[2] // 2 - leng // 2, 0)
    roi = im_th[pt1:pt1+leng, pt2:pt2+leng]

    if roi.size > 0:
        # Resize the image to 28x28
        roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)
        roi = cv2.dilate(roi, (3, 3))

        # Flatten the image to a 1D array
        roi_flattened = roi.reshape(1, -1)

        # Predict using the Random Forest classifier
        prediction = clf.predict(roi_flattened)

        # Display the prediction on the image
        cv2.putText(im, str(int(prediction[0])), (rect[0], rect[1]), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 0), 1)

# Display the resulting image
plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))
plt.title("Predicted Digits")
plt.axis("off")
plt.show()

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
import matplotlib.pyplot as plt

# Define parameters for Random Forest classifier
n_estimators = 100
random_state = 42

# Initialize the Random Forest classifier
clf = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)

# Train the Random Forest model
clf.fit(ar_features, ar_labels)

# Binarize the labels for one-vs-all ROC computation
classes = np.unique(ar_labels)
y_train_bin = label_binarize(ar_labels, classes=classes)
y_test_bin = label_binarize(test_labels, classes=classes)

# Get predicted probabilities
y_score = clf.predict_proba(test_features)

# Plot ROC curves for each class
plt.figure(figsize=(10, 8))
for i, class_label in enumerate(classes):
    # Compute ROC curve and AUC
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc = auc(fpr, tpr)

    # Plot each ROC curve
    plt.plot(fpr, tpr, lw=2, label=f'Class {class_label} (AUC = {roc_auc:.2f})')

# Plot configuration
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Diagonal reference line
plt.title('ROC Curves for Each Class')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='lower right')
plt.grid()
plt.show()

